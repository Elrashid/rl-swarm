{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total Cumulative Reward Monitor - SAPO Experiments\n",
    "\n",
    "This notebook provides **real-time monitoring of total_cumulative_reward** (the primary SAPO paper metric) across all your experiments.\n",
    "\n",
    "**Features:**\n",
    "- Track total cumulative reward (sum across all nodes)\n",
    "- Per-node breakdown\n",
    "- Comparison to baseline\n",
    "- Multi-experiment comparison\n",
    "- Live progress graphs\n",
    "\n",
    "**Usage:**\n",
    "1. Mount Google Drive (Cell 1)\n",
    "2. Configure experiment names (Cell 2)\n",
    "3. Run monitoring cells (Cell 3-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Mount Google Drive & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Set base path (MUST MATCH YOUR EXPERIMENT PATH)\n",
    "GDRIVE_BASE_PATH = '/content/drive/MyDrive/rl-swarm'\n",
    "\n",
    "# Clone repository if needed\n",
    "if not os.path.exists('/content/rl-swarm'):\n",
    "    print(\"Cloning repository...\")\n",
    "    !git clone https://github.com/Elrashid/rl-swarm.git /content/rl-swarm\n",
    "    \n",
    "# Add to path\n",
    "sys.path.append('/content/rl-swarm')\n",
    "\n",
    "print(f\"✓ Setup complete!\")\n",
    "print(f\"  Base path: {GDRIVE_BASE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure Experiments to Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# List your experiment names here\n",
    "EXPERIMENTS = [\n",
    "    'sapo_gpt2_baseline_4loc0ext',     # Baseline\n",
    "    'sapo_gpt2_config2_4loc4ext',      # Config 2 (best)\n",
    "    'sapo_gpt2_adaptive_ij',           # Adaptive I/J\n",
    "]\n",
    "\n",
    "# Primary experiment to monitor (for detailed view)\n",
    "PRIMARY_EXPERIMENT = 'sapo_gpt2_config2_4loc4ext'\n",
    "\n",
    "# Maximum rounds (for progress %)\n",
    "MAX_ROUNDS = 2000\n",
    "\n",
    "# Baseline cumulative reward (for improvement calculation)\n",
    "# Set to None if you don't have baseline yet\n",
    "BASELINE_CUMULATIVE_REWARD = None  # e.g., 250.0\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Primary experiment: {PRIMARY_EXPERIMENT}\")\n",
    "print(f\"  Monitoring {len(EXPERIMENTS)} experiments total\")\n",
    "print(f\"  Max rounds: {MAX_ROUNDS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Quick Status - Total Cumulative Reward\n",
    "\n",
    "**Run this cell anytime to see current total cumulative reward!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from rgym_exp.utils.cumulative_reward_monitor import display_cumulative_progress\n",
    "\n",
    "display_cumulative_progress(\n",
    "    gdrive_base_path=GDRIVE_BASE_PATH,\n",
    "    experiment_name=PRIMARY_EXPERIMENT,\n",
    "    max_rounds=MAX_ROUNDS,\n",
    "    baseline_reward=BASELINE_CUMULATIVE_REWARD\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compare All Experiments\n",
    "\n",
    "**See total cumulative rewards across all your experiments side-by-side**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from rgym_exp.utils.cumulative_reward_monitor import display_experiment_comparison\n",
    "\n",
    "display_experiment_comparison(\n",
    "    gdrive_base_path=GDRIVE_BASE_PATH,\n",
    "    experiment_names=EXPERIMENTS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Plot Cumulative Reward Over Time\n",
    "\n",
    "**Visualize how total cumulative reward grows during training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from rgym_exp.utils.cumulative_reward_monitor import get_cumulative_history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get history for primary experiment\n",
    "history = get_cumulative_history(GDRIVE_BASE_PATH, PRIMARY_EXPERIMENT)\n",
    "\n",
    "if history:\n",
    "    rounds = [h['round'] for h in history]\n",
    "    totals = [h['total_cumulative_reward'] for h in history]\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(rounds, totals, linewidth=2, marker='o', markersize=4)\n",
    "    plt.xlabel('Round', fontsize=12)\n",
    "    plt.ylabel('Total Cumulative Reward', fontsize=12)\n",
    "    plt.title(f'Total Cumulative Reward Progress - {PRIMARY_EXPERIMENT}', \n",
    "              fontsize=14, fontweight='bold')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add current value annotation\n",
    "    if totals:\n",
    "        plt.annotate(f'{totals[-1]:.2f}', \n",
    "                    xy=(rounds[-1], totals[-1]),\n",
    "                    xytext=(10, 10), textcoords='offset points',\n",
    "                    fontsize=10, fontweight='bold',\n",
    "                    bbox=dict(boxstyle='round,pad=0.5', facecolor='yellow', alpha=0.7))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"✓ Plotted {len(history)} rounds\")\n",
    "    print(f\"  Latest total cumulative reward: {totals[-1]:.2f}\")\n",
    "else:\n",
    "    print(\"⚠️  No history data available yet\")\n",
    "    print(\"   Training may not have started or logs are empty\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compare Multiple Experiments (Plot)\n",
    "\n",
    "**Side-by-side comparison of total cumulative reward growth**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from rgym_exp.utils.cumulative_reward_monitor import get_cumulative_history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "colors = ['blue', 'green', 'red', 'orange', 'purple']\n",
    "\n",
    "for i, exp_name in enumerate(EXPERIMENTS):\n",
    "    history = get_cumulative_history(GDRIVE_BASE_PATH, exp_name)\n",
    "    \n",
    "    if history:\n",
    "        rounds = [h['round'] for h in history]\n",
    "        totals = [h['total_cumulative_reward'] for h in history]\n",
    "        \n",
    "        # Short label for legend\n",
    "        label = exp_name.replace('sapo_gpt2_', '').replace('_', ' ')\n",
    "        \n",
    "        plt.plot(rounds, totals, linewidth=2, \n",
    "                label=f\"{label} ({totals[-1]:.0f})\",\n",
    "                color=colors[i % len(colors)],\n",
    "                alpha=0.8)\n",
    "\n",
    "plt.xlabel('Round', fontsize=12)\n",
    "plt.ylabel('Total Cumulative Reward', fontsize=12)\n",
    "plt.title('Total Cumulative Reward Comparison (SAPO Paper Metric)', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='upper left', fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Comparison plot complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Live Monitoring Loop (Optional)\n",
    "\n",
    "**Run this cell for continuous monitoring with auto-refresh**\n",
    "\n",
    "Updates every 60 seconds. Press 'Stop' button to halt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from IPython.display import clear_output\n",
    "from rgym_exp.utils.cumulative_reward_monitor import get_live_cumulative_rewards\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"Starting live monitoring...\")\n",
    "print(\"Press 'Stop' button to halt\\n\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "        print(\"=\"*70)\n",
    "        print(f\"LIVE TOTAL CUMULATIVE REWARD MONITOR - {current_time}\")\n",
    "        print(\"=\"*70)\n",
    "        print()\n",
    "        \n",
    "        for exp_name in EXPERIMENTS:\n",
    "            total, per_node, current_round = get_live_cumulative_rewards(\n",
    "                GDRIVE_BASE_PATH, exp_name\n",
    "            )\n",
    "            \n",
    "            # Short name\n",
    "            short_name = exp_name.replace('sapo_gpt2_', '')\n",
    "            \n",
    "            print(f\"{short_name:25s}:\")\n",
    "            print(f\"  Total Cumulative: {total:8.2f}\")\n",
    "            print(f\"  Round: {current_round:4d} / {MAX_ROUNDS}\")\n",
    "            print(f\"  Nodes: {len(per_node)}\")\n",
    "            \n",
    "            # Progress bar\n",
    "            if MAX_ROUNDS > 0:\n",
    "                progress = min(1.0, current_round / MAX_ROUNDS)\n",
    "                bar_len = 30\n",
    "                filled = int(bar_len * progress)\n",
    "                bar = '█' * filled + '░' * (bar_len - filled)\n",
    "                print(f\"  Progress: [{bar}] {progress*100:.1f}%\")\n",
    "            \n",
    "            print()\n",
    "        \n",
    "        print(\"-\"*70)\n",
    "        print(\"Refreshing in 60 seconds... (Press 'Stop' to halt)\")\n",
    "        \n",
    "        time.sleep(60)\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n✓ Monitoring stopped\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
