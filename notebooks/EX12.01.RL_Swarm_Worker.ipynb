{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# RL Swarm Worker Node (Google Colab)\n",
    "\n",
    "This notebook runs a **worker node** that:\n",
    "- Participates in training\n",
    "- Coordinates with the coordinator node via Google Drive\n",
    "- Shares rollouts via Google Drive (no P2P networking)\n",
    "- No blockchain, Docker, or peer identity required\n",
    "\n",
    "**Before running:**\n",
    "1. Ensure coordinator node is running (using `colab_coordinator.ipynb`)\n",
    "2. Mount your Google Drive (same account as coordinator)\n",
    "3. Set **same EXPERIMENT_NAME** as coordinator\n",
    "4. Set **unique NODE_ID** for this worker\n",
    "5. Run all cells in order\n",
    "\n",
    "**To run multiple workers:** Use this notebook in separate Colab sessions with different NODE_IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config-header"
   },
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "config"
   },
   "outputs": [],
   "source": [
    "# Experiment Configuration",
    "EXPERIMENT_NAME = 'my_first_experiment'  # MUST MATCH COORDINATOR",
    "NODE_ROLE = 'worker'  # DO NOT CHANGE",
    "NODE_ID = 'worker_1'  # MUST BE UNIQUE (worker_1, worker_2, worker_3, etc.)",
    "",
    "# Model Configuration",
    "MODEL_NAME = 'Gensyn/Qwen2.5-0.5B-Instruct'  # Should match coordinator",
    "SEED = 42  # Should match coordinator",
    "",
    "# Training Configuration",
    "MAX_ROUNDS = 1000",
    "NUM_GENERATIONS = 2",
    "NUM_TRANSPLANT_TREES = 2",
    "",
    "# Rollout Sharing Configuration (should match coordinator)",
    "ROLLOUT_PUBLISH_FREQUENCY = 'stage'  # 'generation', 'stage', or 'round'",
    "ROLLOUT_CLEANUP_ENABLED = False      # Set to True to enable cleanup",
    "ROLLOUT_KEEP_LAST_N_ROUNDS = 10      # Only used if cleanup enabled",
    "ROLLOUT_ARCHIVE_OLD = False          # Archive instead of delete",
    "",
    "# Optional: HuggingFace Token (for pushing trained models)",
    "HUGGINGFACE_TOKEN = None  # Set to your token or keep None",
    "",
    "",
    "print(f\"أ¢إ“â€œ Experiment: {EXPERIMENT_NAME}\")",
    "print(f\"أ¢إ“â€œ Node Role: {NODE_ROLE}\")",
    "print(f\"أ¢إ“â€œ Node ID: {NODE_ID}\")",
    "print(f\"أ¢إ“â€œ Model: {MODEL_NAME}\")",
    "print()",
    "print(\"أ¢ع‘آ  Make sure EXPERIMENT_NAME matches the coordinator!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mount-header"
   },
   "source": [
    "## 2. Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount-drive"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Set base path (must be same as coordinator)\n",
    "GDRIVE_BASE_PATH = '/content/drive/MyDrive/rl-swarm'\n",
    "\n",
    "# Check if experiment exists\n",
    "experiment_path = os.path.join(GDRIVE_BASE_PATH, 'experiments', EXPERIMENT_NAME)\n",
    "if not os.path.exists(experiment_path):\n",
    "    print(f\"أ¢â€Œإ’ Experiment '{EXPERIMENT_NAME}' not found!\")\n",
    "    print(f\"   Expected at: {experiment_path}\")\n",
    "    print()\n",
    "    print(\"Make sure:\")\n",
    "    print(\"  1. Coordinator is running\")\n",
    "    print(\"  2. EXPERIMENT_NAME matches the coordinator\")\n",
    "    print(\"  3. You're using the same Google Drive account\")\n",
    "    raise FileNotFoundError(f\"Experiment not found: {EXPERIMENT_NAME}\")\n",
    "else:\n",
    "    print(f\"أ¢إ“â€œ Found experiment: {EXPERIMENT_NAME}\")\n",
    "    print(f\"  Path: {experiment_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "system-header"
   },
   "source": [
    "## 3. System Setup & Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check-gpu"
   },
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"أ¢إ“â€œ GPU available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"أ¢ع‘آ  No GPU detected - training will be slow\")\n",
    "    print(\"  Consider: Runtime > Change runtime type > GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-deps"
   },
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "import os\n",
    "\n",
    "# Change to safe directory first\n",
    "%cd /content\n",
    "\n",
    "# Remove existing directory if it exists\n",
    "if os.path.exists('/content/rl-swarm'):\n",
    "    print(\"Removing existing repository...\")\n",
    "    !rm -rf /content/rl-swarm\n",
    "\n",
    "# Clone fresh copy\n",
    "print(\"Cloning repository...\")\n",
    "!git clone https://github.com/Elrashid/rl-swarm.git /content/rl-swarm\n",
    "\n",
    "# Change to repo directory\n",
    "%cd /content/rl-swarm\n",
    "\n",
    "# Verify clone worked\n",
    "if not os.path.exists('requirements.txt'):\n",
    "    print(\"â‌Œ Clone failed! requirements.txt not found\")\n",
    "    raise FileNotFoundError(\"Repository clone failed\")\n",
    "\n",
    "print(\"âœ“ Repository cloned successfully\")\n",
    "\n",
    "# Install dependencies\n",
    "print(\"Installing dependencies (this may take 3-5 minutes)...\")\n",
    "!pip install -q -r requirements.txt\n",
    "!pip install -q gensyn-genrl==0.1.9\n",
    "\n",
    "print(\"âœ“ Dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "env-header"
   },
   "source": [
    "## 6. Set Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set-env"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set environment variables\n",
    "os.environ['GDRIVE_PATH'] = GDRIVE_BASE_PATH\n",
    "os.environ['EXPERIMENT_NAME'] = EXPERIMENT_NAME\n",
    "os.environ['NODE_ROLE'] = NODE_ROLE\n",
    "os.environ['NODE_ID'] = NODE_ID\n",
    "os.environ['MODEL_NAME'] = MODEL_NAME\n",
    "os.environ['SEED'] = str(SEED)\n",
    "\n",
    "if HUGGINGFACE_TOKEN:\n",
    "    os.environ['HUGGINGFACE_ACCESS_TOKEN'] = HUGGINGFACE_TOKEN\n",
    "\n",
    "\n",
    "print(\"أ¢إ“â€œ Environment variables set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "discovery-header"
   },
   "source": [
    "## 7. Check Peer Discovery\n",
    "\n",
    "Verify that we can discover the coordinator and other workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check-discovery"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "\n",
    "# Set environment variables\n",
    "os.environ['GDRIVE_PATH'] = GDRIVE_BASE_PATH\n",
    "os.environ['EXPERIMENT_NAME'] = EXPERIMENT_NAME\n",
    "os.environ['NODE_ROLE'] = NODE_ROLE\n",
    "os.environ['NODE_ID'] = NODE_ID or f\"worker_{uuid.uuid4().hex[:8]}\"\n",
    "os.environ['MODEL_NAME'] = MODEL_NAME\n",
    "os.environ['SEED'] = str(SEED)\n",
    "\n",
    "# Rollout configuration\n",
    "os.environ['ROLLOUT_PUBLISH_FREQUENCY'] = ROLLOUT_PUBLISH_FREQUENCY\n",
    "os.environ['ROLLOUT_CLEANUP_ENABLED'] = str(ROLLOUT_CLEANUP_ENABLED)\n",
    "os.environ['ROLLOUT_KEEP_LAST_N_ROUNDS'] = str(ROLLOUT_KEEP_LAST_N_ROUNDS)\n",
    "os.environ['ROLLOUT_ARCHIVE_OLD'] = str(ROLLOUT_ARCHIVE_OLD)\n",
    "\n",
    "if HUGGINGFACE_TOKEN:\n",
    "    os.environ['HUGGINGFACE_ACCESS_TOKEN'] = HUGGINGFACE_TOKEN\n",
    "\n",
    "\n",
    "print(\"أ¢إ“â€œ Environment variables set\")\n",
    "print(f\"  Node ID: {os.environ['NODE_ID']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "start-training"
   },
   "outputs": [],
   "source": [
    "from rgym_exp.utils.notebook_utils import run_with_live_output\n",
    "import sys\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"Starting Worker Node: {NODE_ID}\")\n",
    "print(f\"Experiment: {EXPERIMENT_NAME}\")\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "\n",
    "# Run training with live output\n",
    "# Output will stream in real-time below\n",
    "exit_code = run_with_live_output([\n",
    "    sys.executable, '-m', 'rgym_exp.runner.swarm_launcher'\n",
    "])\n",
    "\n",
    "if exit_code == -1:\n",
    "    print(\"\n⚠️  Training interrupted by user\")\n",
    "elif exit_code != 0:\n",
    "    print(f\"\n❌ Training exited with code: {exit_code}\")\n",
    "else:\n",
    "    print(f\"\n✅ Training completed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "monitor-progress"
   },
   "outputs": [],
   "source": [
    "from rgym_exp.utils.experiment_manager import get_experiment_status, get_experiment_metrics\n",
    "import pandas as pd\n",
    "\n",
    "# Get current status\n",
    "status = get_experiment_status(GDRIVE_BASE_PATH, EXPERIMENT_NAME)\n",
    "\n",
    "print(f\"Experiment: {EXPERIMENT_NAME}\")\n",
    "print(f\"Current Round: {status.get('current_round', 0)}\")\n",
    "print(f\"Current Stage: {status.get('current_stage', 0)}\")\n",
    "print(f\"Active Peers: {status.get('active_peers', 0)}\")\n",
    "\n",
    "if 'peer_ids' in status:\n",
    "    print(f\"Peer IDs: {', '.join(status['peer_ids'])}\")\n",
    "\n",
    "if 'total_metric_entries' in status:\n",
    "    print(f\"Total Metric Entries: {status['total_metric_entries']}\")\n",
    "\n",
    "if 'latest_checkpoint' in status:\n",
    "    print(f\"Latest Checkpoint: Round {status['latest_checkpoint']}\")\n",
    "\n",
    "if 'error' in status:\n",
    "    print(f\"âڑ ï¸ڈ  Error: {status['error']}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Load and display recent metrics for this node\n",
    "try:\n",
    "    df = get_experiment_metrics(GDRIVE_BASE_PATH, EXPERIMENT_NAME)\n",
    "    if not df.empty:\n",
    "        print(f\"Recent metrics for {NODE_ID} (last 10 rounds):\")\n",
    "        recent = df[df['node_id'] == NODE_ID].tail(10)\n",
    "        if not recent.empty:\n",
    "            print(recent[['round', 'stage', 'my_reward']].to_string(index=False))\n",
    "        else:\n",
    "            print(f\"No metrics for {NODE_ID} yet\")\n",
    "    else:\n",
    "        print(\"No metrics available yet - training may not have started\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not load metrics: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "source": "# === Real-Time Progress Viewer ===\n# Run this cell anytime to check progress from GDrive\n# Useful if you reconnect after notebook disconnect\n\nimport sys\nsys.path.append('/content/rl-swarm')\n\nfrom rgym_exp.utils.progress_tracker import get_experiment_progress\n\nprogress = get_experiment_progress(GDRIVE_BASE_PATH, EXPERIMENT_NAME)\n\nprint(\"=\"*70)\nprint(\"📊 REAL-TIME PROGRESS FROM GDRIVE\")\nprint(\"=\"*70)\nprint(f\"Experiment: {progress.get('experiment')}\")\nprint()\n\nfor node_id, node_data in progress.get('nodes', {}).items():\n    if 'error' in node_data:\n        print(f\"  {node_id}: {node_data['error']}\")\n    else:\n        print(f\"  {node_id}:\")\n        print(f\"    Latest event: {node_data.get('latest_event')}\")\n        print(f\"    Current round: {node_data.get('latest_round')}\")\n        \n        elapsed_sec = node_data.get('elapsed_seconds', 0)\n        elapsed_hours = elapsed_sec / 3600\n        print(f\"    Elapsed time: {elapsed_hours:.1f} hours\")\n        print()\n\nprint(\"=\"*70)\nprint(\"Note: Progress updates every round. Logs flush every 30s to GDrive.\")\nprint(\"You can access logs directly in Google Drive even while training!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 8.5. Check Real-Time Progress from GDrive (Optional)\n\n**Reconnected after disconnect?** Run this cell to check training progress:\n- Shows current round for each node\n- Displays elapsed time\n- Works even if your notebook disconnected\n\nProgress is saved to GDrive every round, logs flush every 30 seconds.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "resume-header"
   },
   "source": [
    "## 10. Resume Training (If Disconnected)\n",
    "\n",
    "If your Colab session disconnects:\n",
    "1. Re-run all cells above (keep same EXPERIMENT_NAME and NODE_ID)\n",
    "2. The system will automatically resume from the last checkpoint\n",
    "3. Training continues from the last saved round\n",
    "4. Peer discovery will reconnect to coordinator automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "troubleshoot-header"
   },
   "source": [
    "## Troubleshooting\n",
    "\n",
    "### Worker can't find experiment\n",
    "- Verify EXPERIMENT_NAME matches coordinator exactly\n",
    "- Check that coordinator has finished cell 7 (Initialize Experiment)\n",
    "- Ensure using same Google Drive account\n",
    "\n",
    "### No peers discovered\n",
    "- Coordinator must be running and past cell 8\n",
    "- Wait 1-2 minutes for peer discovery to propagate\n",
    "\n",
    "### Out of memory errors\n",
    "- Use smaller model (e.g., Qwen2.5-0.5B instead of 1.5B)\n",
    "- Reduce NUM_GENERATIONS to 1\n",
    "- Enable GPU: Runtime > Change runtime type > GPU\n",
    "\n",
    "### Training too slow\n",
    "- Check GPU is enabled and available\n",
    "- Reduce model size\n",
    "- Check coordinator round duration isn't too short"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "name": "EX12.01.RL_Swarm_Worker.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}