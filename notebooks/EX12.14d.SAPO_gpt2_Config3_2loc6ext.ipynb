{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# SAPO Config 3: 5 GPT-2 Nodes (I=1, J=3) on Single A100 80GB\n\nThis notebook runs **SAPO Config 3** with **heavy swarm collaboration** (75% external rollouts).\n\n**Configuration:**\n- **I=1** (local rollouts per round)\n- **J=3** (external rollouts per round - 75% external)\n- **G=8** (completions per question)\n- **Model**: GPT-2 (124M params)\n- **Hardware**: 5 nodes (1 coordinator + 4 workers) on 1× A100 80GB\n\n**Purpose:** Test heavy swarm collaboration effect.\n\n**Expected Results:**\n- Cumulative reward: **450-650**\n- Improvement vs baseline: **+100-130%**\n- Paper (Qwen2.5-0.5B): 946 (+68% vs their baseline)\n\n**Memory Usage:** ~33 GB peak VRAM (safe on A100 80GB)\n\n**Timeline:** ~21 hours (2000 rounds)\n\n**Scientific Justification:** See `EXPERIMENTAL_DESIGN_JUSTIFICATION.md`\n\n**Paper Reference:** arXiv:2509.08721 - SAPO (Gensyn AI Team, 2025)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. Configuration\n\n**This notebook is pre-configured for Config 3 (I=1, J=3).**\n\nJust run all cells - no changes needed!"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# SAPO Config 3 Experiment Configuration (I=1, J=3)\n# This notebook runs 5 nodes with HEAVY swarm collaboration (75% external)\n\n# ============================================\n# PRE-CONFIGURED FOR CONFIG 3\n# ============================================\nEXPERIMENT_NAME = 'sapo_gpt2_config3_1loc3ext'\nNUM_TRAIN_SAMPLES = 1        # I: Local rollouts per round\nNUM_TRANSPLANT_TREES = 3     # J: External rollouts (75% external)\n\n# ============================================\n# FIXED SETTINGS (same for all experiments)\n# ============================================\nNUM_NODES = 5                # Run 5 nodes (1 coordinator + 4 workers)\nMODEL_NAME = 'gpt2'          # GPT-2 (124M params, fits memory)\nNUM_GENERATIONS = 8          # G: Completions per question (like paper)\nMAX_ROUNDS = 2000            # Train for 2000 rounds (like paper)\nSEED = 42                    # For reproducibility\n\n# Rollout Sharing Configuration\nROLLOUT_PUBLISH_FREQUENCY = 'stage'  # When to share rollouts\nROLLOUT_CLEANUP_ENABLED = True       # Enable cleanup to save space\nROLLOUT_KEEP_LAST_N_ROUNDS = 20      # Keep recent rollouts only\nROLLOUT_ARCHIVE_OLD = False          # Don't archive (saves space)\n\n# Optional: HuggingFace Token\nHUGGINGFACE_TOKEN = None  # Set to your token or keep None\n\nprint(\"=\"*60)\nprint(f\"SAPO Config 3 Experiment\")\nprint(\"=\"*60)\nprint(f\"✓ Nodes: {NUM_NODES} (1 coordinator + 4 workers on single A100 80GB)\")\nprint(f\"✓ Model: {MODEL_NAME}\")\nprint(f\"✓ Config: I={NUM_TRAIN_SAMPLES}, J={NUM_TRANSPLANT_TREES}, G={NUM_GENERATIONS}\")\nprint(f\"✓ Experiment: {EXPERIMENT_NAME}\")\nprint(f\"✓ Max Rounds: {MAX_ROUNDS}\")\nprint()\nprint(f\"Expected VRAM: ~33 GB (80 GB available)\")\nprint(f\"Expected Time: ~21 hours\")\nprint()\nprint(\"📊 Config 3 (heavy swarm collaboration - 75% external)\")\nprint(\"   Expected reward: 450-650 (+100-130% vs baseline)\")\nprint(\"   Paper (Qwen2.5): 946 (+68%)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Set base path (MUST BE SAME ACROSS ALL NODES)\n",
    "GDRIVE_BASE_PATH = '/content/drive/MyDrive/rl-swarm'\n",
    "os.makedirs(GDRIVE_BASE_PATH, exist_ok=True)\n",
    "\n",
    "print(f\"✓ Google Drive mounted at: {GDRIVE_BASE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. System Setup & GPU Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import torch\n\nprint(\"=\"*60)\nprint(\"GPU Verification\")\nprint(\"=\"*60)\n\nif torch.cuda.is_available():\n    gpu_name = torch.cuda.get_device_name(0)\n    total_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n    \n    print(f\"✓ GPU: {gpu_name}\")\n    print(f\"✓ Total VRAM: {total_memory:.1f} GB\")\n    print()\n    \n    # Check if we have enough memory\n    required_memory = NUM_NODES * 6.5  # 6.5 GB per GPT-2 node\n    print(f\"Memory Requirements:\")\n    print(f\"  Required: {required_memory:.1f} GB ({NUM_NODES} nodes × 6.5 GB)\")\n    print(f\"  Available: {total_memory:.1f} GB\")\n    print(f\"  Margin: {total_memory - required_memory:.1f} GB\")\n    print()\n    \n    if total_memory < required_memory:\n        print(\"⚠️  WARNING: Insufficient VRAM!\")\n        print(f\"   Need at least {required_memory:.0f} GB, but have {total_memory:.1f} GB\")\n        print(f\"   Consider reducing NUM_NODES to {int(total_memory / 6.5)}\")\n        raise RuntimeError(\"Insufficient GPU memory\")\n    elif total_memory < 75:\n        print(\"⚠️  WARNING: Tight fit! Expected A100 80GB.\")\n        print(f\"   Have {total_memory:.1f} GB. May still work, but monitor memory closely.\")\n    else:\n        print(f\"✅ Sufficient VRAM for {NUM_NODES} GPT-2 nodes\")\nelse:\n    raise RuntimeError(\"No GPU detected! Select A100 GPU runtime: Runtime > Change runtime type > A100 GPU\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Clone Repository & Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "%cd /content\n\n# Remove existing directory if it exists\nif os.path.exists('/content/rl-swarm'):\n    print(\"Removing existing repository...\")\n    !rm -rf /content/rl-swarm\n\n# Clone fresh copy\nprint(\"Cloning repository...\")\n!git clone https://github.com/Elrashid/rl-swarm.git /content/rl-swarm\n\n# Change to repo directory\n%cd /content/rl-swarm\n\n# Verify clone worked\nif not os.path.exists('requirements.txt'):\n    raise FileNotFoundError(\"Repository clone failed - requirements.txt not found\")\n\nprint(\"✓ Repository cloned successfully\")\nprint()\n\n# Install dependencies\nprint(\"Installing dependencies (this may take 3-5 minutes)...\")\nprint(\"Note: Warnings about protobuf versions can be ignored\")\nprint()\n\n# Install main dependencies (without -q to show errors)\n!pip install -r requirements.txt\n\n# Install GenRL explicitly\n!pip install gensyn-genrl==0.1.9\n\n# Fix protobuf version explicitly to avoid conflicts\n!pip install 'protobuf>=4.25.0,<5.0'\n\n# Verify reasoning-gym was installed\ntry:\n    import reasoning_gym\n    print()\n    print(\"✓ Dependencies installed successfully\")\n    print(\"✓ reasoning-gym verified\")\nexcept ImportError as e:\n    print()\n    print(\"❌ ERROR: reasoning-gym failed to install!\")\n    print(\"   Please report this issue with the error above\")\n    raise"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Initialize Experiment\n",
    "\n",
    "**Note:** Only the coordinator (node_0) creates the experiment structure. Workers will join it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rgym_exp.utils.experiment_manager import init_experiment\n",
    "\n",
    "# Initialize experiment structure in Google Drive (coordinator creates it)\n",
    "config_overrides = {\n",
    "    'training.max_round': MAX_ROUNDS,\n",
    "    'training.num_generations': NUM_GENERATIONS,\n",
    "    'training.num_transplant_trees': NUM_TRANSPLANT_TREES,\n",
    "    'training.num_train_samples': NUM_TRAIN_SAMPLES,\n",
    "    'training.seed': SEED,\n",
    "}\n",
    "\n",
    "init_experiment(\n",
    "    gdrive_base_path=GDRIVE_BASE_PATH,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    config_overrides=config_overrides\n",
    ")\n",
    "\n",
    "print(f\"✓ Experiment initialized: {EXPERIMENT_NAME}\")\n",
    "print(f\"  Path: {GDRIVE_BASE_PATH}/experiments/{EXPERIMENT_NAME}\")\n",
    "print(f\"  Config: I={NUM_TRAIN_SAMPLES}, J={NUM_TRANSPLANT_TREES}, G={NUM_GENERATIONS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6. Launch 5-Node Swarm (KEY CELL)\n\n**This cell:**\n1. Spawns 5 separate Python processes\n2. Each process runs `swarm_launcher.py` with unique NODE_ID\n3. All processes share GPU 0 (CUDA_VISIBLE_DEVICES=0)\n4. Coordinator (node_0) manages round progression\n5. Workers (node_1-4) follow coordinator\n\n**Logs:** Each node writes to Google Drive at `{GDRIVE_BASE_PATH}/experiments/{EXPERIMENT_NAME}/logs/`\n\n**Monitor:** Use next cell (Cell 7) to track progress in real-time"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import subprocess\nimport os\nimport time\nfrom datetime import datetime\n\nprint(\"=\"*60)\nprint(f\"Launching {NUM_NODES}-Node SAPO Swarm\")\nprint(\"=\"*60)\nprint(f\"Experiment: {EXPERIMENT_NAME}\")\nprint(f\"Model: {MODEL_NAME}\")\nprint(f\"Config: I={NUM_TRAIN_SAMPLES}, J={NUM_TRANSPLANT_TREES}, G={NUM_GENERATIONS}\")\nprint(f\"Hardware: All {NUM_NODES} nodes on single GPU (A100 80GB)\")\nprint(\"=\"*60)\nprint()\n\nprocesses = []\nstart_time = time.time()  # For ETA calculation\n\nfor node_id in range(NUM_NODES):\n    # Environment variables for this node\n    env = os.environ.copy()\n    env['NODE_ID'] = f'node_{node_id}'\n    env['NODE_ROLE'] = 'coordinator' if node_id == 0 else 'worker'\n    env['MODEL_NAME'] = MODEL_NAME\n    env['NUM_TRAIN_SAMPLES'] = str(NUM_TRAIN_SAMPLES)\n    env['NUM_TRANSPLANT_TREES'] = str(NUM_TRANSPLANT_TREES)\n    env['NUM_GENERATIONS'] = str(NUM_GENERATIONS)\n    env['MAX_ROUNDS'] = str(MAX_ROUNDS)\n    env['EXPERIMENT_NAME'] = EXPERIMENT_NAME\n    env['GDRIVE_PATH'] = GDRIVE_BASE_PATH\n    env['CUDA_VISIBLE_DEVICES'] = '0'  # All nodes share GPU 0\n    env['SEED'] = str(SEED + node_id)  # Different seed per node (diversity)\n    env['ROLLOUT_PUBLISH_FREQUENCY'] = ROLLOUT_PUBLISH_FREQUENCY\n    env['ROLLOUT_CLEANUP_ENABLED'] = str(ROLLOUT_CLEANUP_ENABLED)\n    env['ROLLOUT_KEEP_LAST_N_ROUNDS'] = str(ROLLOUT_KEEP_LAST_N_ROUNDS)\n    env['ROLLOUT_ARCHIVE_OLD'] = str(ROLLOUT_ARCHIVE_OLD)\n    \n    if HUGGINGFACE_TOKEN:\n        env['HUGGINGFACE_ACCESS_TOKEN'] = HUGGINGFACE_TOKEN\n    \n    # Launch process\n    import sys\n    process = subprocess.Popen(\n        [sys.executable, '-m', 'rgym_exp.runner.swarm_launcher'],\n        env=env,\n        cwd='/content/rl-swarm'\n    )\n    processes.append(process)\n    \n    role = \"COORDINATOR\" if node_id == 0 else \"WORKER     \"\n    print(f\"✓ Started node_{node_id} ({role}) - PID: {process.pid:5d}\")\n    \n    # Stagger startup to avoid race conditions\n    time.sleep(10)\n\nprint()\nprint(f\"✅ All {NUM_NODES} nodes launched successfully!\")\nprint(f\"✓ Training will run for approximately 21 hours ({MAX_ROUNDS} rounds)\")\nprint(f\"✓ Logs location: {GDRIVE_BASE_PATH}/experiments/{EXPERIMENT_NAME}/logs/\")\nprint()\nprint(\"⚠️  Keep this notebook open (browser tab active)\")\nprint(\"⚠️  Colab may disconnect after 12-24 hours\")\nprint(\"⚠️  Training will continue, but use Cell 7 to monitor\")\nprint()\nprint(\"Monitor progress in Cell 7 below...\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 7. Monitor Training Progress\n\n**This cell:**\n- Shows real-time status of all 5 nodes\n- Displays GPU memory usage\n- Shows current round/stage progress\n- Estimates time remaining (ETA)\n- Updates every 60 seconds\n\n**To stop training:** Click \"Stop\" button or press Ctrl+C\n\n**Note:** You can re-run this cell anytime to check status"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Starting training monitor...\")\n",
    "print(\"Press 'Stop' button or Ctrl+C to interrupt\\n\")\n",
    "\n",
    "monitor_start_time = time.time()\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        # Check process status\n",
    "        running = sum(1 for p in processes if p.poll() is None)\n",
    "        completed = NUM_NODES - running\n",
    "        \n",
    "        current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        elapsed_hours = (time.time() - start_time) / 3600\n",
    "        \n",
    "        print(\"=\"*70)\n",
    "        print(f\" SAPO Training Monitor - {EXPERIMENT_NAME}\")\n",
    "        print(f\" Time: {current_time} | Elapsed: {elapsed_hours:.1f}h\")\n",
    "        print(\"=\"*70)\n",
    "        print()\n",
    "        \n",
    "        # Node status\n",
    "        print(f\"Nodes:\")\n",
    "        print(f\"  Running:   {running}/{NUM_NODES}\")\n",
    "        print(f\"  Completed: {completed}/{NUM_NODES}\")\n",
    "        print()\n",
    "        \n",
    "        # GPU memory\n",
    "        if torch.cuda.is_available():\n",
    "            allocated = torch.cuda.memory_allocated(0) / 1e9\n",
    "            reserved = torch.cuda.memory_reserved(0) / 1e9\n",
    "            total = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "            \n",
    "            utilization = (reserved / total) * 100\n",
    "            \n",
    "            print(f\"GPU Memory ({torch.cuda.get_device_name(0)}):\")\n",
    "            print(f\"  Allocated: {allocated:5.1f} GB\")\n",
    "            print(f\"  Reserved:  {reserved:5.1f} GB / {total:.1f} GB ({utilization:.1f}%)\")\n",
    "            print(f\"  Free:      {total - reserved:5.1f} GB\")\n",
    "            \n",
    "            # Warning if memory is high\n",
    "            if utilization > 90:\n",
    "                print(f\"  ⚠️  WARNING: High memory usage! May OOM soon.\")\n",
    "            elif utilization > 75:\n",
    "                print(f\"  ⚠️  Memory usage elevated. Monitoring closely.\")\n",
    "            \n",
    "            print()\n",
    "        \n",
    "        # Training progress\n",
    "        try:\n",
    "            from rgym_exp.utils.experiment_manager import get_experiment_status\n",
    "            status = get_experiment_status(GDRIVE_BASE_PATH, EXPERIMENT_NAME)\n",
    "            \n",
    "            if status:\n",
    "                current_round = status.get('current_round', 0)\n",
    "                progress_pct = (current_round / MAX_ROUNDS) * 100\n",
    "                \n",
    "                print(f\"Training Progress:\")\n",
    "                print(f\"  Round:     {current_round:4d} / {MAX_ROUNDS} ({progress_pct:5.1f}%)\")\n",
    "                print(f\"  Stage:     {status.get('current_stage', 0)}\")\n",
    "                print(f\"  Active peers: {status.get('active_peers', 0)}\")\n",
    "                \n",
    "                # ETA calculation\n",
    "                if current_round > 10:  # Wait for stable estimate\n",
    "                    hours_per_round = elapsed_hours / current_round\n",
    "                    remaining_rounds = MAX_ROUNDS - current_round\n",
    "                    eta_hours = remaining_rounds * hours_per_round\n",
    "                    \n",
    "                    print(f\"  ETA:       {eta_hours:.1f} hours (~{eta_hours/24:.1f} days)\")\n",
    "                    \n",
    "                    # Progress bar\n",
    "                    bar_length = 40\n",
    "                    filled = int(bar_length * progress_pct / 100)\n",
    "                    bar = '█' * filled + '░' * (bar_length - filled)\n",
    "                    print(f\"  [{bar}]\")\n",
    "                \n",
    "                print()\n",
    "                \n",
    "                # Recent performance\n",
    "                try:\n",
    "                    from rgym_exp.utils.experiment_manager import get_experiment_metrics\n",
    "                    df = get_experiment_metrics(GDRIVE_BASE_PATH, EXPERIMENT_NAME)\n",
    "                    \n",
    "                    if not df.empty:\n",
    "                        cumulative_reward = df['my_reward'].sum()\n",
    "                        recent_reward = df.tail(10)['my_reward'].mean()\n",
    "                        \n",
    "                        print(f\"Rewards:\")\n",
    "                        print(f\"  Cumulative: {cumulative_reward:6.2f}\")\n",
    "                        print(f\"  Recent avg: {recent_reward:6.2f} (last 10 rounds)\")\n",
    "                        print()\n",
    "                except Exception:\n",
    "                    pass  # Metrics not available yet\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Progress: Unable to load status ({e})\")\n",
    "            print()\n",
    "        \n",
    "        # Instructions\n",
    "        print(\"-\"*70)\n",
    "        print(\"Press 'Stop' button or Ctrl+C to halt training\")\n",
    "        print(f\"Next update in 60 seconds...\")\n",
    "        \n",
    "        # Exit if all completed\n",
    "        if running == 0:\n",
    "            print()\n",
    "            print(\"=\"*70)\n",
    "            print(\"✅ All nodes completed successfully!\")\n",
    "            print(\"=\"*70)\n",
    "            break\n",
    "        \n",
    "        time.sleep(60)  # Update every minute\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"⚠️  Training interrupted by user\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nTerminating all node processes...\")\n",
    "    \n",
    "    for i, p in enumerate(processes):\n",
    "        if p.poll() is None:\n",
    "            print(f\"  Stopping node_{i}... (PID: {p.pid})\")\n",
    "            p.terminate()\n",
    "    \n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Force kill if still running\n",
    "    for i, p in enumerate(processes):\n",
    "        if p.poll() is None:\n",
    "            print(f\"  Force killing node_{i}... (PID: {p.pid})\")\n",
    "            p.kill()\n",
    "    \n",
    "    print(\"\\n✓ All processes terminated\")\n",
    "    print(\"\\n💾 Note: Training state is checkpointed.\")\n",
    "    print(\"   Re-run this notebook to resume from last checkpoint.\")\n",
    "\n",
    "finally:\n",
    "    # Close log files\n",
    "    for log_file in log_files:\n",
    "        try:\n",
    "            log_file.close()\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. View Results & Analysis\n",
    "\n",
    "**After training completes, run this cell to:**\n",
    "- Load all metrics\n",
    "- Calculate cumulative rewards per node\n",
    "- Compare to paper's results\n",
    "- Generate plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rgym_exp.utils.experiment_manager import get_experiment_metrics\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(f\"Results: {EXPERIMENT_NAME}\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Config: I={NUM_TRAIN_SAMPLES}, J={NUM_TRANSPLANT_TREES}, G={NUM_GENERATIONS}\")\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Nodes: {NUM_NODES}\")\n",
    "print()\n",
    "\n",
    "# Load metrics\n",
    "df = get_experiment_metrics(GDRIVE_BASE_PATH, EXPERIMENT_NAME)\n",
    "\n",
    "if not df.empty:\n",
    "    # Calculate cumulative reward per node\n",
    "    node_rewards = df.groupby('node_id')['my_reward'].sum().sort_values(ascending=False)\n",
    "    total_reward = node_rewards.sum()\n",
    "    \n",
    "    print(\"Cumulative Rewards by Node:\")\n",
    "    for node_id, reward in node_rewards.items():\n",
    "        print(f\"  {node_id:10s}: {reward:7.2f}\")\n",
    "    print(f\"  {'TOTAL':10s}: {total_reward:7.2f}\")\n",
    "    print()\n",
    "    \n",
    "    # Compare to paper's results\n",
    "    print(\"Comparison to Paper (Qwen2.5-0.5B):\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    if NUM_TRANSPLANT_TREES == 0:\n",
    "        paper_reward = 562\n",
    "        config_name = \"Baseline (8/0)\"\n",
    "        paper_improvement = \"—\"\n",
    "    elif NUM_TRAIN_SAMPLES == 6 and NUM_TRANSPLANT_TREES == 2:\n",
    "        paper_reward = 854\n",
    "        config_name = \"Config 1 (6/2)\"\n",
    "        paper_improvement = \"+52%\"\n",
    "    elif NUM_TRAIN_SAMPLES == 4 and NUM_TRANSPLANT_TREES == 4:\n",
    "        paper_reward = 1093\n",
    "        config_name = \"Config 2 (4/4) **BEST**\"\n",
    "        paper_improvement = \"+94%\"\n",
    "    elif NUM_TRAIN_SAMPLES == 2 and NUM_TRANSPLANT_TREES == 6:\n",
    "        paper_reward = 946\n",
    "        config_name = \"Config 3 (2/6)\"\n",
    "        paper_improvement = \"+68%\"\n",
    "    else:\n",
    "        paper_reward = None\n",
    "        config_name = f\"Custom ({NUM_TRAIN_SAMPLES}/{NUM_TRANSPLANT_TREES})\"\n",
    "        paper_improvement = \"N/A\"\n",
    "    \n",
    "    print(f\"  Configuration: {config_name}\")\n",
    "    if paper_reward:\n",
    "        print(f\"  Paper (Qwen2.5):  {paper_reward:7.2f} ({paper_improvement})\")\n",
    "        print(f\"  Ours (GPT-2):     {total_reward:7.2f} (~{total_reward/paper_reward*100:.1f}% of paper)\")\n",
    "    else:\n",
    "        print(f\"  Ours (GPT-2):     {total_reward:7.2f}\")\n",
    "    print()\n",
    "    \n",
    "    # If we have baseline results, calculate improvement\n",
    "    baseline_path = GDRIVE_BASE_PATH + '/experiments/sapo_gpt2_baseline_8loc0ext'\n",
    "    try:\n",
    "        baseline_df = get_experiment_metrics(GDRIVE_BASE_PATH, 'sapo_gpt2_baseline_8loc0ext')\n",
    "        if not baseline_df.empty and NUM_TRANSPLANT_TREES > 0:\n",
    "            baseline_reward = baseline_df['my_reward'].sum()\n",
    "            improvement = ((total_reward - baseline_reward) / baseline_reward) * 100\n",
    "            print(f\"Improvement vs Our Baseline:\")\n",
    "            print(f\"  Baseline (GPT-2): {baseline_reward:7.2f}\")\n",
    "            print(f\"  This config:      {total_reward:7.2f}\")\n",
    "            print(f\"  Improvement:      {improvement:+7.1f}%\")\n",
    "            print()\n",
    "            \n",
    "            if improvement > 94:\n",
    "                print(\"✅ HYPOTHESIS CONFIRMED! GPT-2 shows >94% improvement\")\n",
    "                print(\"   Weaker models benefit MORE from swarm (as predicted)\")\n",
    "            elif improvement > 50:\n",
    "                print(\"✅ Strong swarm effect demonstrated (+{:.1f}%)\".format(improvement))\n",
    "            else:\n",
    "                print(\"⚠️  Lower improvement than expected\")\n",
    "            print()\n",
    "    except:\n",
    "        pass  # Baseline not run yet\n",
    "    \n",
    "    # Plot rewards over time\n",
    "    print(\"Generating plots...\")\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Plot 1: Cumulative reward per node\n",
    "    for node_id in df['node_id'].unique():\n",
    "        node_df = df[df['node_id'] == node_id].sort_values('round')\n",
    "        ax1.plot(node_df['round'], node_df['my_reward'].cumsum(), \n",
    "                 label=node_id, alpha=0.7)\n",
    "    \n",
    "    ax1.set_xlabel('Round', fontsize=12)\n",
    "    ax1.set_ylabel('Cumulative Reward', fontsize=12)\n",
    "    ax1.set_title(f'{config_name} - Cumulative Rewards Over Time', fontsize=14, fontweight='bold')\n",
    "    ax1.legend(loc='upper left', fontsize=8)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Average reward per round (smoothed)\n",
    "    round_avg = df.groupby('round')['my_reward'].mean()\n",
    "    # Apply moving average\n",
    "    window_size = 100\n",
    "    smoothed = round_avg.rolling(window=window_size, center=True).mean()\n",
    "    \n",
    "    ax2.plot(round_avg.index, round_avg.values, alpha=0.3, color='gray', label='Raw')\n",
    "    ax2.plot(smoothed.index, smoothed.values, linewidth=2, color='blue', label=f'Smoothed ({window_size}-round MA)')\n",
    "    \n",
    "    ax2.set_xlabel('Round', fontsize=12)\n",
    "    ax2.set_ylabel('Average Reward', fontsize=12)\n",
    "    ax2.set_title(f'{config_name} - Average Reward per Round', fontsize=14, fontweight='bold')\n",
    "    ax2.legend(fontsize=10)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save plot\n",
    "    plot_path = f'/content/drive/MyDrive/rl-swarm/results_{EXPERIMENT_NAME}.png'\n",
    "    plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "    print(f\"✓ Plot saved to: {plot_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"❌ No metrics available yet\")\n",
    "    print(\"   Training may not have started or metrics file is missing\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}