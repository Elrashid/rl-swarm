# Google Drive + Colab Configuration for RL Swarm
# No blockchain, Docker, or authentication required

# Google Drive Configuration
gdrive:
  base_path: ${oc.env:GDRIVE_PATH,/content/drive/MyDrive/rl-swarm}
  experiment_name: ${oc.env:EXPERIMENT_NAME,default_experiment}
  node_role: ${oc.env:NODE_ROLE,worker}  # 'coordinator' or 'worker'
  node_id: ${oc.env:NODE_ID,node_0}

# Logs go to Google Drive (persistent across Colab sessions)
log_dir: ${gdrive.base_path}/experiments/${gdrive.experiment_name}/logs/${gdrive.node_id}

# Hydra configuration
hydra:
  run:
    dir: ${log_dir}
  job_logging:
    handlers:
      console:
        level: INFO
    root:
      level: DEBUG

# Training configuration
training:
  max_round: 1000000
  max_stage: 1
  num_generations: 2
  num_transplant_trees: 2
  seed: ${oc.env:SEED,42}
  dtype: 'float32'
  checkpoint_frequency: 10  # Save checkpoint every N rounds

# Evaluation configuration
eval:
  judge_base_url: "https://swarm-judge.internal-apps-central1.clusters.gensyn.ai"

# Rollout Sharing Configuration Guide:
#
# rollout_publish_frequency:
#   - 'generation': Publish after each generation (most frequent, highest API usage)
#   - 'stage': Publish after each stage (recommended, balanced)
#   - 'round': Publish after each round (least frequent, lowest API usage)
#
# rollout_retention:
#   cleanup_enabled: false = Keep all rollouts forever (good for debugging)
#   cleanup_enabled: true = Enable automatic cleanup
#     keep_last_n_rounds: N = Keep only last N rounds
#     archive_old_rollouts: true = Move old rollouts to archive instead of deleting
#
# Storage estimates (4 nodes, 2 stages/round):
#   - 100 rounds: ~8 MB
#   - 1000 rounds: ~80 MB
#   - Google Drive free tier: 15 GB (can store ~187,500 rounds)

# Coordinator Manager (for coordinator node only)
coordinator_manager:
  advancement_strategy: hybrid  # 'time_based', 'completion_based', or 'hybrid'
  round_duration_minutes: 10
  min_submission_percent: 0.5
  max_round_duration_minutes: 20

# Game Manager configuration
game_manager:
  _target_: rgym_exp.src.manager.SwarmGameManager
  max_stage: ${training.max_stage}
  max_round: ${training.max_round}
  log_dir: ${log_dir}
  hf_token: ${oc.env:HUGGINGFACE_ACCESS_TOKEN,null}
  hf_push_frequency: 20
  run_mode: "train_and_evaluate"
  bootnodes: []  # No bootnodes needed in GDrive mode
  prg_game_config: null  # PRG game disabled in GDrive mode

  # Game state
  game_state:
    _target_: genrl.state.game_state.GameState
    round: 0
    stage: 0

  # Reward manager
  reward_manager:
    _target_: genrl.rewards.DefaultRewardManager
    reward_fn_store:
      _target_: genrl.rewards.reward_store.RewardFnStore
      max_rounds: ${training.max_round}
      reward_fn_stores:
        - _target_: genrl.rewards.reward_store.RoundRewardFnStore
          num_stages: ${training.max_stage}
          reward_fns:
            - _target_: rgym_exp.src.rewards.RGRewards

  # Trainer configuration
  trainer:
    _target_: rgym_exp.src.trainer.GRPOTrainerModule
    models:
      - _target_: transformers.AutoModelForCausalLM.from_pretrained
        pretrained_model_name_or_path: ${oc.env:MODEL_NAME,Gensyn/Qwen2.5-0.5B-Instruct}
    config:
      _target_: genrl.trainer.grpo_trainer.GRPOTrainerConfig
      dtype: ${training.dtype}
      epsilon: 0.2
      epsilon_high: 0.28
      num_generations: ${training.num_generations}
    log_with: wandb
    log_dir: ${log_dir}
    judge_base_url: ${eval.judge_base_url}

  # Data manager
  data_manager:
    _target_: rgym_exp.src.data.ReasoningGymDataManager
    yaml_config_path: "rgym_exp/src/datasets.yaml"
    num_train_samples: 2
    num_evaluation_samples: 0
    num_generations: ${training.num_generations}
    system_prompt_id: 'default'
    seed: ${training.seed}
    num_transplant_trees: ${training.num_transplant_trees}

  # Communication (Google Drive)
  communication:
    _target_: rgym_exp.communication.gdrive_backend.GDriveCommunicationBackend
    gdrive_rollout_sharing: null  # Will be injected by swarm_launcher
    node_id: null  # Will be injected by swarm_launcher
    experiment_name: ${gdrive.experiment_name}

    # Rollout sharing configuration
    rollout_publish_frequency: 'stage'  # Options: 'generation', 'stage', 'round'

    # Fetching behavior
    fetch_max_peers: 10  # How many peers to fetch from
    fetch_timeout_seconds: 30  # How long to wait for Drive API
    cache_rollouts: true  # Enable local caching

    # Retention policy
    rollout_retention:
      cleanup_enabled: false  # Set to true to enable cleanup
      keep_last_n_rounds: 10  # Keep 10 most recent rounds
      archive_old_rollouts: false  # Set to true to archive instead of delete
      archive_path: ${gdrive.base_path}/archives/${gdrive.experiment_name}/

  # Google Drive Coordinator (replaces blockchain)
  coordinator:
    _target_: rgym_exp.src.gdrive_coordinator.GDriveSwarmCoordinator
    gdrive_path: ${gdrive.base_path}/experiments/${gdrive.experiment_name}
    node_role: ${gdrive.node_role}
    round_check_interval: 30

# Model pools (for auto-selection based on hardware)
default_large_model_pool:
  - nvidia/AceInstruct-1.5B
  - dnotitia/Smoothie-Qwen3-1.7B
  - Gensyn/Qwen2.5-1.5B-Instruct

default_small_model_pool:
  - Gensyn/Qwen2.5-0.5B-Instruct
  - Qwen/Qwen3-0.6B
