Map:   0%|          | 0/4 [00:00<?, ? examples/s]Map: 100%|##########| 4/4 [00:00<00:00, 324.66 examples/s]
Map:   0%|          | 0/4 [00:00<?, ? examples/s]Map: 100%|##########| 4/4 [00:00<00:00, 339.21 examples/s]
Map:   0%|          | 0/4 [00:00<?, ? examples/s]Map: 100%|##########| 4/4 [00:00<00:00, 350.03 examples/s]
Map:   0%|          | 0/4 [00:00<?, ? examples/s]Map: 100%|##########| 4/4 [00:00<00:00, 336.67 examples/s]
ERROR:rgym_exp.vendor.genrl.logging_utils.global_defs:Exception occurred during game run.
Traceback (most recent call last):
  File "/content/rl-swarm/rgym_exp/vendor/genrl/game/game_manager.py", line 169, in run_game
    self.run_game_round()  # Loops through stages until end of round signal is received
    ^^^^^^^^^^^^^^^^^^^^^
  File "/content/rl-swarm/rgym_exp/src/manager.py", line 141, in run_game_round
    self.trainer.train(self.state, self.data_manager, self.rewards)
  File "/content/rl-swarm/rgym_exp/vendor/genrl/trainer/grpo_trainer.py", line 380, in train
    global_step = self.step(
                  ^^^^^^^^^^
  File "/content/rl-swarm/rgym_exp/vendor/genrl/trainer/grpo_trainer.py", line 445, in step
    loss = self.compute_loss(self.model, model_inputs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/content/rl-swarm/rgym_exp/vendor/genrl/trainer/grpo_trainer.py", line 298, in compute_loss
    per_token_logps = self._get_per_token_logps(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/content/rl-swarm/rgym_exp/vendor/genrl/trainer/grpo_trainer.py", line 238, in _get_per_token_logps
    logits = model(
             ^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/gpt2/modeling_gpt2.py", line 1068, in forward
    transformer_outputs = self.transformer(
                          ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/gpt2/modeling_gpt2.py", line 925, in forward
    outputs = block(
              ^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_layers.py", line 93, in __call__
    return self._gradient_checkpointing_func(partial(super().__call__, **kwargs), *args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/_compile.py", line 53, in inner
    return disable_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 929, in _fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py", line 488, in checkpoint
    return CheckpointFunction.apply(function, preserve, *args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/autograd/function.py", line 576, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py", line 262, in forward
    outputs = run_function(*args)
              ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/gpt2/modeling_gpt2.py", line 413, in forward
    attn_output, self_attn_weights = self.attn(
                                     ^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/gpt2/modeling_gpt2.py", line 313, in forward
    query_states, key_states, value_states = self.c_attn(hidden_states).split(self.split_size, dim=2)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/pytorch_utils.py", line 122, in forward
    x = torch.addmm(self.bias, x.view(-1, x.size(-1)), self.weight)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 150.00 MiB. GPU 0 has a total capacity of 22.16 GiB of which 27.62 MiB is free. Process 28164 has 726.00 MiB memory in use. Process 28937 has 9.76 GiB memory in use. Process 29109 has 3.56 GiB memory in use. Process 29746 has 6.04 GiB memory in use. Process 29844 has 2.05 GiB memory in use. Of the allocated memory 1.59 GiB is allocated by PyTorch, and 240.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Stack (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/content/rl-swarm/rgym_exp/runner/swarm_launcher.py", line 298, in <module>
    main()
  File "/content/rl-swarm/rgym_exp/runner/swarm_launcher.py", line 283, in main
    game_manager.run_game()
  File "/content/rl-swarm/rgym_exp/vendor/genrl/game/game_manager.py", line 171, in run_game
    get_logger().exception(
